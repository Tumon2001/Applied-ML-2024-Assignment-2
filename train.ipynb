{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import csv\n",
    "import nltk\n",
    "import pandas\n",
    "import mlflow\n",
    "import sklearn\n",
    "import numpy as np\n",
    "from sklearn.metrics import average_precision_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from textblob import TextBlob\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.metrics import classification_report, f1_score, accuracy_score, confusion_matrix, auc, precision_recall_curve, mean_squared_error\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold, cross_val_score, train_test_split, learning_curve\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from mlflow.models import infer_signature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/tumon/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Dowloading NLTK stopwords\n",
    "nltk.download(\"stopwords\")\n",
    "\n",
    "def preprocess_data(data):\n",
    "\n",
    "    # Remove characters other than English letters and digits\n",
    "    data['text'] = data['text'].apply(lambda x: re.sub(r'[^a-zA-Z0-9\\s]', '', x))\n",
    "\n",
    "    # Convert to lowercase\n",
    "    data['text'] = data['text'].apply(lambda x: x.lower())\n",
    "\n",
    "    # Remove stopwords\n",
    "    s = set(stopwords.words(\"english\"))\n",
    "    data['text'] = data['text'].apply(lambda x: ' '.join([word for word in x.split() if word not in s and word]))\n",
    "\n",
    "    return data\n",
    "\n",
    "texts = pandas.read_csv(\"raw_data.csv\")\n",
    "texts = preprocess_data(texts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Splitting the preprocessed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data splitting: 80% to training data, 5% to validation, 15% to test data\n",
    "def split_data(data, test_size = 0.2, validation_size = 0.25, output_path = './'):\n",
    "\n",
    "    # Split the data into train and test sets\n",
    "    train_data, test_data = train_test_split(data, test_size = test_size, random_state = 1)\n",
    "\n",
    "    # Further split the test data into validation and test sets\n",
    "    validation_data, test_data = train_test_split(test_data, test_size = validation_size, random_state = 1)\n",
    "\n",
    "    train_data.to_csv(f'{output_path}/train.csv', index = False)\n",
    "    validation_data.to_csv(f'{output_path}/validation.csv', index = False)\n",
    "    test_data.to_csv(f'{output_path}/test.csv', index = False)\n",
    "\n",
    "split_data(texts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading the preprocessed train, validation, and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading preprocessed train data\n",
    "X_train = pandas.read_csv(\"train.csv\")\n",
    "y_train = X_train['spam']\n",
    "X_train_text = X_train['text']\n",
    "\n",
    "# Loading preprocessed validation data\n",
    "X_validation = pandas.read_csv(\"validation.csv\") \n",
    "y_validation = X_validation['spam']\n",
    "X_validation_text = X_validation['text']\n",
    "\n",
    "# Loading preprocessed test data\n",
    "X_test = pandas.read_csv(\"test.csv\")\n",
    "y_test = X_test['spam']\n",
    "X_test_text = X_test['text']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vectorizer = TfidfVectorizer(max_features = 50000)\n",
    "\n",
    "X_train_tfidf = tfidf_vectorizer.fit_transform(X_train_text)\n",
    "X_validation_tfidf = tfidf_vectorizer.transform(X_validation_text)\n",
    "X_test_tfidf = tfidf_vectorizer.transform(X_test_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setting up MLflow tracking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.set_tracking_uri(\"http://127.0.0.1:5000\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [\n",
    "    (\"Logistic Regression\", LogisticRegression()),\n",
    "    (\"Random Forest Classifier\", RandomForestClassifier()),\n",
    "    (\"Support Vector Machine\", SVC(probability=True))\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building, tracking, and registering the three models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tumon/.virtualenvs/AML_HW_1/lib/python3.11/site-packages/mlflow/types/utils.py:393: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n",
      "  warnings.warn(\n",
      "/home/tumon/.virtualenvs/AML_HW_1/lib/python3.11/site-packages/_distutils_hack/__init__.py:18: UserWarning: Distutils was imported before Setuptools, but importing Setuptools also replaces the `distutils` module in `sys.modules`. This may lead to undesirable behaviors or errors. To avoid these issues, avoid using distutils directly, ensure that setuptools is installed in the traditional way (e.g. not an editable install), and/or make sure that setuptools is always imported before distutils.\n",
      "  warnings.warn(\n",
      "/home/tumon/.virtualenvs/AML_HW_1/lib/python3.11/site-packages/_distutils_hack/__init__.py:33: UserWarning: Setuptools is replacing distutils.\n",
      "  warnings.warn(\"Setuptools is replacing distutils.\")\n",
      "Successfully registered model 'Logistic Regression'.\n",
      "2024/02/20 23:18:02 INFO mlflow.store.model_registry.abstract_store: Waiting up to 300 seconds for model version to finish creation. Model name: Logistic Regression, version 1\n",
      "Created version '1' of model 'Logistic Regression'.\n",
      "/home/tumon/.virtualenvs/AML_HW_1/lib/python3.11/site-packages/mlflow/types/utils.py:393: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n",
      "  warnings.warn(\n",
      "/home/tumon/.virtualenvs/AML_HW_1/lib/python3.11/site-packages/_distutils_hack/__init__.py:18: UserWarning: Distutils was imported before Setuptools, but importing Setuptools also replaces the `distutils` module in `sys.modules`. This may lead to undesirable behaviors or errors. To avoid these issues, avoid using distutils directly, ensure that setuptools is installed in the traditional way (e.g. not an editable install), and/or make sure that setuptools is always imported before distutils.\n",
      "  warnings.warn(\n",
      "/home/tumon/.virtualenvs/AML_HW_1/lib/python3.11/site-packages/_distutils_hack/__init__.py:33: UserWarning: Setuptools is replacing distutils.\n",
      "  warnings.warn(\"Setuptools is replacing distutils.\")\n",
      "Successfully registered model 'Random Forest Classifier'.\n",
      "2024/02/20 23:18:07 INFO mlflow.store.model_registry.abstract_store: Waiting up to 300 seconds for model version to finish creation. Model name: Random Forest Classifier, version 1\n",
      "Created version '1' of model 'Random Forest Classifier'.\n",
      "/home/tumon/.virtualenvs/AML_HW_1/lib/python3.11/site-packages/mlflow/types/utils.py:393: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n",
      "  warnings.warn(\n",
      "/home/tumon/.virtualenvs/AML_HW_1/lib/python3.11/site-packages/_distutils_hack/__init__.py:18: UserWarning: Distutils was imported before Setuptools, but importing Setuptools also replaces the `distutils` module in `sys.modules`. This may lead to undesirable behaviors or errors. To avoid these issues, avoid using distutils directly, ensure that setuptools is installed in the traditional way (e.g. not an editable install), and/or make sure that setuptools is always imported before distutils.\n",
      "  warnings.warn(\n",
      "/home/tumon/.virtualenvs/AML_HW_1/lib/python3.11/site-packages/_distutils_hack/__init__.py:33: UserWarning: Setuptools is replacing distutils.\n",
      "  warnings.warn(\"Setuptools is replacing distutils.\")\n",
      "Successfully registered model 'Support Vector Machine'.\n",
      "2024/02/20 23:18:51 INFO mlflow.store.model_registry.abstract_store: Waiting up to 300 seconds for model version to finish creation. Model name: Support Vector Machine, version 1\n",
      "Created version '1' of model 'Support Vector Machine'.\n"
     ]
    }
   ],
   "source": [
    "for model_name, model in models:\n",
    "    with mlflow.start_run() as run:\n",
    "\n",
    "        model.fit(X_train_tfidf, y_train)\n",
    "\n",
    "        y_pred = model.predict(X_validation_tfidf)\n",
    "        signature = infer_signature(X_test, y_pred)\n",
    "\n",
    "        mlflow.log_params(model.get_params())\n",
    "        mlflow.log_metrics({\"mse\": mean_squared_error(y_validation, y_pred)})\n",
    "\n",
    "        mlflow.sklearn.log_model(\n",
    "            sk_model=model,\n",
    "            artifact_path=\"sklearn-model\",\n",
    "            signature=signature,\n",
    "            registered_model_name=model_name,\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Printing AUCPR for the three models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "abc02aef2dae4e21afeb2bd996163bc7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Name: Logistic Regression, Validation AUCPR = 0.999770345798363\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "97ac7784fcb041dc9c53361e15acad6a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Name: Random Forest Classifier, Validation AUCPR = 0.9974920067388685\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c91b1cc9b7340b69a26fe0a0e00c89e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Name: SVC, Validation AUCPR = 0.9997981905712987\n"
     ]
    }
   ],
   "source": [
    "# Define the run IDs and model names for the three models\n",
    "run_info = [\n",
    "    {\"run_id\": \"bda6b42d1c4e42fc882ea84c39c7fcd0\", \"model_name\": \"Logistic Regression\"},\n",
    "    {\"run_id\": \"637ff480f61846c5b6218465ea136fc6\", \"model_name\": \"Random Forest Classifier\"},\n",
    "    {\"run_id\": \"985c9edd9b34412598b217427d73188a\", \"model_name\": \"SVC\"}\n",
    "]\n",
    "\n",
    "for info in run_info:\n",
    "    # Load the model artifact for the current run ID\n",
    "    model = mlflow.sklearn.load_model(f\"runs:/{info['run_id']}/sklearn-model\")\n",
    "\n",
    "    y_proba_val = model.predict_proba(X_validation_tfidf)[:, 1]\n",
    "    precision_val, recall_val, _ = precision_recall_curve(y_validation, y_proba_val)\n",
    "    aucpr_val = auc(recall_val, precision_val)\n",
    "\n",
    "    print(f\"Model Name: {info['model_name']}, Validation AUCPR = {aucpr_val}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AML_HW_1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
